---
title: 2.2. Hello, Agent!
short-title: Hello, Agent!
description: "Instantiate some SwimOS Web Agents."
group: Getting Started
layout: documentation
redirect_from:
  - /rust/developer-guide/hello-agent
  - /rust/developer-guide/hello-agent.html
---

Having completed the setup, we're ready to continue our tutorial application. We'll now incorporate SwimOS's fundamental building blocks - agents.

# Agents

A Stateful Object is a simple structural representation of an entity that lives amongst your streaming data. A Stateful Object continuously consumes updates of synced state and for each update, it computes new state that automatically gets synced to listeners. In SwimOS, these Stateful Objects are named Agents and the state contained within them is exposed through Lanes; these are similar to `Durable State` in Akka and `State` in Flink but the state is addressable using a URI relative to an instance of an Agent.

Agents are defined using structs that can be automatically derived using the declared macros below. Lets define one in our `server/src/main.rs` file:

```rust
#[derive(AgentLaneModel)]
#[projections]
pub struct ExampleAgent {
    lane: ValueLane<i32>,
}

/// A lifecycle must be associated with an agent so that it can react to any events
/// that happen during its lifetime.
#[derive(Clone)]
pub struct ExampleLifecycle;

/// Here we bind this struct's implementation to our agent above.
#[lifecycle(ExampleAgent)]
impl ExampleLifecycle {
    /// This method will be invoked when the agent starts.
    #[on_start]
    pub fn on_start(
        &self,
        context: HandlerContext<ExampleAgent>,
    ) -> impl EventHandler<ExampleAgent> {
        context.get_agent_uri().and_then(move |uri| {
            context.effect(move || {
                println!("Starting agent at: {}", uri);
            })
        })
    }

    /// This method will be invoked when the agent stops.
    #[on_stop]
    pub fn on_stop(
        &self,
        context: HandlerContext<ExampleAgent>,
    ) -> impl EventHandler<ExampleAgent> {
        context.get_agent_uri().and_then(move |uri| {
            context.effect(move || {
                println!("Stopping agent at: {}", uri);
            })
        })
    }

    /// This method will be invoked when the `ValueLane` named `"lane"` receives
    /// an update.
    #[on_event(lane)]
    pub fn on_event(
        &self,
        context: HandlerContext<ExampleAgent>,
        value: &i32,
    ) -> impl EventHandler<ExampleAgent> {
        let n = *value;
        context.effect(move || {
            println!("Setting value to: {}", n);
        })
    }
}


```

{% capture alert_text %}
Any type parameters used by a Lane must implement the <a href="https://doc.rust-lang.org/std/marker/trait.Send.html" style="color: lightblue; font-weight: bold;">Send</a> and <a href="{% link _rust_backend/forms.md %}" style="color: lightblue; font-weight: bold;">Form</a> traits.
{% endcapture %}

{% include alert.html title='Note' text=alert_text %}

In our example above, we have added a single `ValueLane` to our agent that stores a single `i32` instance that is addressable through a lane URI of `"lane"`

# Starting the server

To build and run a server, we first need to map the schema of agents to a `ServerBuilder` and configure any properties.

To register agents with a `ServerBuilder`, we need to associate the URIs of the agents with the agents. We do this as follows in `server/src/main.rs`:

```rust
#[tokio::main]
async fn main() -> Result<(), Box<dyn Error + Send + Sync>> {
    // Here we create a dynamic route named "/example/:name" to use for our `ExampleAgent`.
    let route = RoutePattern::parse_str("/example/:name}")?;
    let lifecycle = ExampleLifecycle;
    // We can think of this as creating our agent factory that will be used to create
    // instances of our agent.
    let agent = AgentModel::new(ExampleAgent::default, lifecycle.into_lifecycle());

    let server = ServerBuilder::with_plane_name("Plane")
        .update_config(|config| {
            // Ensure the agent stops fairly quickly.
            config.agent_runtime.inactive_timeout = Duration::from_secs(20);
        })
        // Register the agent againt the route. Now, we can send events to `"/example/:name"`
        // and a new agent will be started for every unique path that is addressed.
        .add_route(route, agent)
        .build()
        // An error may be returned from this future if there is a connection issue or
        // a path collision.
        .await?;

    // We've now got a future for the server and a handle that may be used to stop
    // the server or receive the address that the listener has bound to.
    let (task, handle) = server.run();
    let shutdown = manage_handle(handle);

    let (_, result) = tokio::join!(shutdown, task);

    result?;
    println!("Server stopped successfully.");
    Ok(())
}

// Utility function for awaiting the listener's socket address and listening for a
// stop signal in the terminal.
async fn manage_handle(mut handle: ServerHandle) {
    if let Some(addr) = handle.bound_addr().await {
        println!("Bound to: {}", addr);
        tokio::signal::ctrl_c()
            .await
            .expect("Failed to register interrupt handler.");
    }

    println!("Stopping server.");
    handle.stop();
}
```

# Interacting with the server

To interact with our server, we need to use the `swimos_client` crate and connect to the lane that we wish to interact with using a Downlink. Downlinks provide the ability to execute state retreival and update operations against lanes on a server.

We can downlink to a lane as follows in our `client/src/main.rs`:

```rust
#[tokio::main]
async fn main() {
    // Build a Swim Client using the default configuration.
    // The `build` method returns a `SwimClient` instance and its internal
    // runtime future that is spawned below.
    let (client, task) = SwimClientBuilder::default().build().await;
    let _client_task = tokio::spawn(task);
    let handle = client.handle();

    // We pass in the port that the server bound to and access it from the
    // command line arguments provided.
    let args = std::env::args().collect::<Vec<_>>();
    let port = match args.get(1) {
        Some(port) => usize::from_str(port.as_ref()).unwrap(),
        None => panic!("No argument provided"),
    };

    // Build a path the downlink.
    let path = RemotePath::new(
        format!("ws://0.0.0.0:{}", port),
        // We can provide any agent URI that matches the pattern
        // "/example/:id"
        "/example/1",
        // This is the URI of the ValueLane<i32> in our ExampleAgent
        "lane",
    );

    let lifecycle = BasicValueDownlinkLifecycle::<usize>::default()
        // Register an event handler that is invoked when the downlink connects to the  agent.
        .on_linked_blocking(|| println!("Downlink linked"))
        // Register an event handler that is invoked when the downlink synchronises its state
        // with the agent.
        .on_synced_blocking(|value| println!("Downlink synced with: {value:?}"))
        // Register an event handler that is invoked when the downlink receives an event.
        .on_event_blocking(|value| println!("Downlink event: {value:?}"));

    // Build our downlink.
    //
    // This operation may fail due to a connection issue.
    let downlink = handle
        .value_downlink::<usize>(path.clone())
        .lifecycle(lifecycle)
        .downlink_config(DownlinkConfig::default())
        .open()
        .await
        .expect("Failed to open downlink");

    for i in 0..10 {
        // Update the agent's state.
        downlink.set(i).await.expect("Failed to set downlink state");
    }

    tokio::signal::ctrl_c()
        .await
        .expect("Failed to listen for ctrl-c.");
}
```

# Running

We're now ready to run our server and client applications. First, we need to start the server.

In the `server` directory run:

```shell
cargo run
```

Once the server has started and is listening for events you will see in the console the port that the server bound to:

```
Bound to: 0.0.0.0:56693
```

Copy the port that the server bound to (in the above example, 56693) and in the `client` directory execute the command below and paste the port.

```shell
cargo run -- 56693
```

## Client output

In our client terminal, we'll see the below output:

```
Downlink linked
Downlink synced with: 0
Downlink event: 0
Downlink event: 1
Downlink event: 2
Downlink event: 3
Downlink event: 4
Downlink event: 5
Downlink event: 6
Downlink event: 7
Downlink event: 8
Downlink event: 9
```

Lets have a look at the order of these events. The execution flow is `linked -> synced -> events`.

When a downlink first connects to a lane, it sends a request to register for events (known as a link request) and it receives back a `linked` response envelope. The same happens for a sync request but before we receive a `synced` response, any state from the lane is transmitted to the client. Once our downlink has synced, we then receive any events from the lane; which in our example, we trigger. It's important to note, that state is transmitted to **all** linked registrants, which in this instance, includes our client's downlink.

It's also possible to register a lifecycle event which is triggered when the downlink unlinks. This may be useful if you need to fire a subsequent event for when the agent stops (perhaps due to a timeout) or the server stops. It is also possible to create lifecycle event handlers that execute asynchronously or share state which is provided to the closure as an argument.

## Server output

After our configured timeout of 20 seconds, we'll see the below output in our server terminal:

```
Starting agent at: /example/1
Setting value to: 0
Setting value to: 1
Setting value to: 2
Setting value to: 3
Setting value to: 4
Setting value to: 5
Setting value to: 6
Setting value to: 7
Setting value to: 8
Setting value to: 9
Stopping agent at: /example/1
```

Above, we can see that our `on_start` lifecycle event handler was invoked before any event handlers were invoked. Once no events have been received for our defined period of 20 seconds the agent will shutdown and propagate an `unlinked` envelope to all `linked` peers. A variety of event handlers may be defined for lanes which may be used to build up a workflow that reacts to incoming messages, potentially updates an agent's state, and propagates state to linked peers.

# Full code

The full code for this page is available at: [todo-link](todo-link).
